{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be8dbd1d",
   "metadata": {},
   "source": [
    "## Binary Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99566878",
   "metadata": {},
   "source": [
    "This project aims to build a binary classification  to differentiate  posts from two subreddits  from Reddit.Using Natural Language Processing ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d0d570",
   "metadata": {},
   "source": [
    "### Data Collection "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8abbf74",
   "metadata": {},
   "source": [
    "We collect data by  webscrapping  using API  from Reddit . The data is from two subreddit the \"Urban Planning \" and \"Sustainability\". We used this link \"url = 'https://api.pushshift.io//reddit/search/submission'\".  We collected  2000 post from each subreddit which made in total around 4000 rows of data. From the post we are going to use the title and self_text of the post."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59836748",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b00dfe30",
   "metadata": {},
   "source": [
    "In this stage , we are did some data cleanning , removed some empty rows,combined the title and self text in one column to facilitate the using the Nature Language Processing wich will hep to change the text into numerical features for modelling. \n",
    "\n",
    "In order to understand the and analyse the txt data we looked ata the distribution o the word count and the length of the post \n",
    "We look into the distribution of the overall length of the posts and word counts  , the distribution is  right skewed which means that the most post are between 0-200 words or between 0-1000 characters for both subreddit.\n",
    "\n",
    "In the EDA we also looked at the most commonly used words overall and also in the respective subreddit.We used  different method to analyse the word from the post .The countvectorizer which count the occurrence of the word in our dataset and TF-IDF vectorizer means Term Frequency - Inverse Document Frequency. This is a statistic that is based on the frequency of a word in the dataset but it also provides a numerical representation of how important a word is for statistical analysis.\n",
    "\n",
    "Using these methods we also look at the combination of 2 words ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b424376",
   "metadata": {},
   "source": [
    "### Modeling "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861a51e0",
   "metadata": {},
   "source": [
    "For the modelling part  , we start by making a train -test split  with test size of 1/3 of the dataframe.\n",
    "We are going to fit different model to compare them and one of the way to work with it is to use pipe  where we can use a transformer and an estimator wich is the model.\n",
    "\n",
    "We decided to use the Multimonial Naives Bayes, Random forest  and a KNN.After instantiating the model we use a confusion matrix to look at the True positive, True Negative, False Pasitive and False negative.\n",
    "The metrics we used are  Recall means  from all the positive classes, how many we predicted correctly.\n",
    "Precision means  from all the classes we have predicted as positive, how many are actually positive.\n",
    "Accuracy means From all the classes (positive and negative), how many of them we have predicted correctly.\n",
    "We will also use F1_score which is a good compromise for the precision and recall. The high they are the better."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c20f898",
   "metadata": {},
   "source": [
    "### Evaluation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3ba2ed",
   "metadata": {},
   "source": [
    "Using the Random Forest Classifier model  \n",
    "The model  has an Accuracy score of **99%** on training data and **87%** on unseen data which is an indication of high variance.It also means on data that the model trainned on it capable of classifiying correctly 99% of the posts into sustainability or urban planning but perform on 87% on new posts.\n",
    "\n",
    "\n",
    "Precision is 85% which means that for all the posts the model predicted to be from sustainability 85% are actually from the sustainability posts .\n",
    "\n",
    "The recall is 91%  which means that from all the posts we predicted 91% correctly both from sustainability and urban planning.\n",
    "The f-1 score which is a good compromise for the precision and recall is 88%.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64fb8634",
   "metadata": {},
   "source": [
    "Using the Multinomial Naives Bayes model which look into probabilities \n",
    "The model  has A score of 94% on training data and 90% on unseen data which is an indication of high variance but less than the one from Random forest .\n",
    "\n",
    "\n",
    "Precision is 90% which means that for all the posts the model predicted to be from sustainability 90% are actually from the sustainability posts .\n",
    "The recall is 89%  which means that from all the posts we predicted 89 % correctly both from sustainability and urban planning.\n",
    "The f-1 score is which is a good compromise for the precision and recall 90%.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9faec13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85e3f86",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dsirfx_py38] *",
   "language": "python",
   "name": "conda-env-dsirfx_py38-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
